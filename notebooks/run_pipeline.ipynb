{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eeecd48-9bbe-4bdc-af24-748b134b2d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import os\n",
    "\n",
    "from tml.data.get_l1_l2 import (\n",
    "    prepare_level1_training_set,\n",
    "    prepare_level2_training_set,\n",
    "    prune_test_set,\n",
    ")\n",
    "from tml.data.load_data import load_and_preprocess_data\n",
    "from tml.models.model import BinaryClassificationLightning\n",
    "from tml.plotting.plotting import tml_plots\n",
    "from tml.training.trainer import train_model\n",
    "from tml.utils.utils import load_config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83378c8-e377-448d-9838-1c8f268714fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to run the training and evaluation\n",
    "def pipeline(config_path):\n",
    "    \n",
    "    config = load_config(config_path)\n",
    "\n",
    "    # Initialize logger\n",
    "    logger = TensorBoardLogger(\"logs\", name=config['sample_name'])\n",
    "\n",
    "    cols = range(1, config['num_cols']+1)\n",
    "    config['input_dim'] = len(cols) - 1\n",
    "\n",
    "    # Load data and normalize\n",
    "    load_dict =load_and_preprocess_data(config['input_path'], cols)\n",
    "    out1 = load_dict['out1']\n",
    "    out2_var = load_dict['out2_var']\n",
    "\n",
    "    for cnt in range(config['sampling_num']):\n",
    "        np.random.seed(cnt + 1)\n",
    "        # Prepare Level 1 training data\n",
    "        train_set_L1 = prepare_level1_training_set(load_dict['pos_ind'],\n",
    "                                                   load_dict['neg_ind'],\n",
    "                                                   load_dict['all_set'],\n",
    "                                                   cnt\n",
    "                                                   )\n",
    "\n",
    "        # Level 1 training\n",
    "        print(f\"Level 1 training: subset {cnt+1}\")\n",
    "        model_L1, _ = train_model(\n",
    "            train_set=train_set_L1,\n",
    "            input_dim=config['input_dim'],\n",
    "            nb_classes=config['nb_classes']-1,\n",
    "            batch_size=config['batch_size'],\n",
    "            max_epochs=config['epochs'],\n",
    "            dropout_rate=None,\n",
    "            learning_rate=config['learning_rate'],\n",
    "            logger=logger\n",
    "        )\n",
    "\n",
    "        # Level 1 testing\n",
    "        print(f\"Level 1 test: subset {cnt+1}\")\n",
    "        y_pred = model_L1.predict(load_dict['test_set'][:, 1:])\n",
    "\n",
    "        # Pruning\n",
    "        TPs, TNs = prune_test_set(load_dict['test_set'],\n",
    "                                  y_pred,\n",
    "                                  lower_thresh=config['lower_threshold'],\n",
    "                                  upper_thresh=config['upper_threshold'])\n",
    "\n",
    "        # Prepare Level 2 training data\n",
    "        train_set_L2 = prepare_level2_training_set(TPs, TNs, load_dict['test_set'], cnt)\n",
    "\n",
    "        # Level 2 training\n",
    "        print(f\"Level 2 training: subset {cnt+1}\")\n",
    "        model_L2, checkpoint_path_L2 = train_model(\n",
    "            train_set=train_set_L2,\n",
    "            input_dim=config['input_dim'],\n",
    "            nb_classes=config['nb_classes']-1,\n",
    "            batch_size=config['batch_size'],\n",
    "            max_epochs=config['epochs'],\n",
    "            dropout_rate=config['dropout_rate'],\n",
    "            learning_rate=config['learning_rate'],\n",
    "            logger=logger,\n",
    "            cnt=cnt+1,\n",
    "            save=True\n",
    "        )\n",
    "\n",
    "        # Ensure out1 has two dimensions\n",
    "        print(f\"out1 dims: {out1.ndim}\")\n",
    "        if out1.ndim == 1:\n",
    "            out1 = out1.reshape(-1, 1)\n",
    "\n",
    "        # Level 2 testing\n",
    "        print(f\"Level 2 test: subset {cnt+1}\")\n",
    "        y_pred_all = model_L2.predict(load_dict['all_set'][:, 1:])\n",
    "        y_pred_all = y_pred_all.reshape(-1, 1)\n",
    "        out1 = np.hstack((out1, y_pred_all))\n",
    "\n",
    "        # Predict with dropout\n",
    "        y_pred_dropout = model_L2.predict_with_dropout(load_dict['all_set'][:, 1:], config['drop_it'])\n",
    "\n",
    "        if out2_var.ndim == 1:\n",
    "            out2_var = out2_var.reshape(-1, 1)\n",
    "        \n",
    "        y_pred_var = np.var(y_pred_dropout, axis=0).reshape(-1, 1)\n",
    "        out2_var = np.hstack((out2_var, y_pred_var))\n",
    "\n",
    "    # Calculate final results and save\n",
    "    print(\"Calculate final results\")\n",
    "    y_pred_mean_1 = np.mean(out1[:, 1:], axis=1)\n",
    "    y_pred_mvar = np.mean(out2_var[:, 1:], axis=1)\n",
    "    final = np.column_stack((y_pred_mean_1, y_pred_mvar))\n",
    "    \n",
    "\n",
    "    # Plot and calculate thresholds\n",
    "    os.makedirs(config['out_path'], exist_ok=True)\n",
    "    \n",
    "\n",
    "    thr = tml_plots(final,\n",
    "                    load_dict['neg_ind'],\n",
    "                    load_dict['hpos_ind'],\n",
    "                    config['pscore_cf'],\n",
    "                    config['auc_cf'],\n",
    "                    config['tpr_cf'],\n",
    "                    f\"{config['out_path']}/{config['sample_name']}\"\n",
    "                    )\n",
    "\n",
    "    final = np.column_stack((final, np.repeat(\"PASS\", len(y_pred_mvar))))\n",
    "    final[final[:,1].astype(float) > thr, 2] = \"FAIL_Uncertain\"\n",
    "    final[final[:,0].astype(float) <= config['pscore_cf'], 2] = \"FAIL_LowScore\"\n",
    "    save = np.column_stack((load_dict['names'], final))\n",
    "    header = ['Mutation', 'Type', 'Probability_Score', 'Uncertainty_Score', 'Result']\n",
    "    pd.DataFrame(save.astype(str)).to_csv(f\"{config['out_path']}/{config['sample_name']}_scores.csv\", header=header, index=None)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cd4230-259b-4a25-b7fa-0847ac4886d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc02d587-fe99-44b5-848d-a1cea6f1dcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load config\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--config', default=\"tml/configs/config.yaml\", help='Path to config file.')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    pipeline(args.config)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9467a7d6-7251-48aa-bdfe-94c850d87f41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da22a838-273c-4ebf-8bcb-503ec7035bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fe3ad9-7acd-4d6a-8cea-db1e9f6a6d49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tml]",
   "language": "python",
   "name": "conda-env-tml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
